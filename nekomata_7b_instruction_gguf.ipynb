{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbtPLzzERuIMIZpp+ezfgE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chottokun/colaboratory/blob/main/nekomata_7b_instruction_gguf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/rinna/nekomata-7b-instruction-gguf/resolve/main/nekomata-7b-instruction.Q4_K_M.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPoEV4nfuomi",
        "outputId": "2fae7b3a-ee1c-42ad-d680-9615832cfc42"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-22 13:53:35--  https://huggingface.co/rinna/nekomata-7b-instruction-gguf/resolve/main/nekomata-7b-instruction.Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.74, 3.163.189.37, 3.163.189.90, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/ef/11/ef1122ea9fed6a06175c060d3a1c5b337015ae588a3f24b202acfe85870fb4b5/d6dfc7e9d38bc0a4ae87fdf4480cf94ce1ebbc57af575b509cd84767ad3c5b6f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27nekomata-7b-instruction.Q4_K_M.gguf%3B+filename%3D%22nekomata-7b-instruction.Q4_K_M.gguf%22%3B&Expires=1703512415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMzUxMjQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VmLzExL2VmMTEyMmVhOWZlZDZhMDYxNzVjMDYwZDNhMWM1YjMzNzAxNWFlNTg4YTNmMjRiMjAyYWNmZTg1ODcwZmI0YjUvZDZkZmM3ZTlkMzhiYzBhNGFlODdmZGY0NDgwY2Y5NGNlMWViYmM1N2FmNTc1YjUwOWNkODQ3NjdhZDNjNWI2Zj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=MjP1yq3459aHcdpgZpBDtSzFJgYwPMKLp2OvW%7EXBEqGuXANEa8dBhSc6H7CBxwnEZv0sN4F25QcnRxmFqL32OwLi541VhokTyC1uk8Ttz3Nhy9iXI2LRyVc8cMN8IwFREc82cX7KdNgzXCacscAAwlSbTpPYaC3pUOcfWrWmQQKHrJszjk-Q9F3sJgjtXsrs1n3J8QzeOcxYblm%7EXNJgjfmVogCvBOkeRIWTyvjRMGBsMtPDL34Is-8SsgPTW0gDuQmvcrDDHyoG2bFfI4CtkWPGm68i%7E%7EfgaHKDZ05N8xD-Qwzul6dzxU8JRudhnCnRVO5Uv8em9iezVEIgpPFRcQ__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
            "--2023-12-22 13:53:35--  https://cdn-lfs-us-1.huggingface.co/repos/ef/11/ef1122ea9fed6a06175c060d3a1c5b337015ae588a3f24b202acfe85870fb4b5/d6dfc7e9d38bc0a4ae87fdf4480cf94ce1ebbc57af575b509cd84767ad3c5b6f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27nekomata-7b-instruction.Q4_K_M.gguf%3B+filename%3D%22nekomata-7b-instruction.Q4_K_M.gguf%22%3B&Expires=1703512415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMzUxMjQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VmLzExL2VmMTEyMmVhOWZlZDZhMDYxNzVjMDYwZDNhMWM1YjMzNzAxNWFlNTg4YTNmMjRiMjAyYWNmZTg1ODcwZmI0YjUvZDZkZmM3ZTlkMzhiYzBhNGFlODdmZGY0NDgwY2Y5NGNlMWViYmM1N2FmNTc1YjUwOWNkODQ3NjdhZDNjNWI2Zj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=MjP1yq3459aHcdpgZpBDtSzFJgYwPMKLp2OvW%7EXBEqGuXANEa8dBhSc6H7CBxwnEZv0sN4F25QcnRxmFqL32OwLi541VhokTyC1uk8Ttz3Nhy9iXI2LRyVc8cMN8IwFREc82cX7KdNgzXCacscAAwlSbTpPYaC3pUOcfWrWmQQKHrJszjk-Q9F3sJgjtXsrs1n3J8QzeOcxYblm%7EXNJgjfmVogCvBOkeRIWTyvjRMGBsMtPDL34Is-8SsgPTW0gDuQmvcrDDHyoG2bFfI4CtkWPGm68i%7E%7EfgaHKDZ05N8xD-Qwzul6dzxU8JRudhnCnRVO5Uv8em9iezVEIgpPFRcQ__&Key-Pair-Id=KCD77M1F0VK2B\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 13.224.14.34, 13.224.14.99, 13.224.14.84, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|13.224.14.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4899217600 (4.6G) [binary/octet-stream]\n",
            "Saving to: ‘nekomata-7b-instruction.Q4_K_M.gguf’\n",
            "\n",
            "nekomata-7b-instruc 100%[===================>]   4.56G   208MB/s    in 24s     \n",
            "\n",
            "2023-12-22 13:53:59 (196 MB/s) - ‘nekomata-7b-instruction.Q4_K_M.gguf’ saved [4899217600/4899217600]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
      ],
      "metadata": {
        "id": "MzsuFPD2xv49"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "import ctypes\n",
        "llm =Llama(model_path=\"/content/llama.cpp/nekomata-7b-instruction.Q4_K_M.gguf\", n_gpu_layers=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zj1qWrJx3io",
        "outputId": "daa3f6cb-d70b-4a63-ba7b-1bf97dfb9d36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(instruction, input):\n",
        "  prompt = f\"\"\"\n",
        "  以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\n${instruction}\\n\\n### 入力:\\n${input}\\n\\n### 応答:\\n\n",
        "  \"\"\"\n",
        "  output = llm(prompt,max_tokens=1024)\n",
        "  return output[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "McmeK67PyuSi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "instruction = \"次の日本語を英語に翻訳してください。\"\n",
        "input = \"\"\"\n",
        "大規模言語モデル（だいきぼげんごモデル、英: large language model、LLM）は、多数のパラメータ（数千万から数十億）を持つ人工ニューラルネットワークで構成されるコンピュータ言語モデルで、膨大なラベルなしテキストを使用して自己教師あり学習または半教師あり学習によって訓練が行われる。\n",
        "\"\"\"\n",
        "print(generate(instruction, input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLJw4CYVyE1g",
        "outputId": "6101b57b-a987-4ecc-decf-18609bd51cde"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A large language model (LLM) is a computer natural language model that consists of an artificial neural network with millions or billions of parameters, and is trained using self-supervised or semi-supervised learning on vast amounts of unlabeled text.\n",
            "CPU times: user 9.71 s, sys: 22.1 ms, total: 9.73 s\n",
            "Wall time: 9.72 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "instruction = \"次の文章を１０語で要約してください。\"\n",
        "input = \"\"\"\n",
        "大規模言語モデル（だいきぼげんごモデル、英: large language model、LLM）は、多数のパラメータ（数千万から数十億）を持つ人工ニューラルネットワークで構成されるコンピュータ言語モデルで、膨大なラベルなしテキストを使用して自己教師あり学習または半教師あり学習によって訓練が行われる。\n",
        "\"\"\"\n",
        "print(generate(instruction, input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfggAfmCzoOd",
        "outputId": "289a82dd-cb54-48da-8d0e-1d225f51ef4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LLM(だいきぼげんごモデル、英: large language model、LLM)は、人工ニューラルネットワークで構成されるコンピュータ言語モデルで、多数のパラメータ（数千万から数十億）を持ちます。教師あり学習によって訓練が行われる。\n",
            "CPU times: user 14.1 s, sys: 19.7 ms, total: 14.1 s\n",
            "Wall time: 14.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "instruction = \"あなたは優秀なAIモデルです。ユーザーの入力に対して回答とその理由を詳しく述べてください。\"\n",
        "input = \"\"\"\n",
        "まどか☆マギカでは誰が一番かわいい?\n",
        "\"\"\"\n",
        "print(generate(instruction, input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdiAJlhX0Txx",
        "outputId": "bd63b2a2-9a7f-4b38-e614-0a522da6af77"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1.巴マミさん (魔法少女に変身すると美しさは2倍、強さも2倍になる！）\n",
            "2.暁美ほむらさん（完璧なプロヒーローで、いつも助けてくれます！\n",
            "3.佐倉杏子さん（彼女は、友達と一緒にいるときの姿が一番かわいい。\n",
            "CPU times: user 15.2 s, sys: 30 ms, total: 15.3 s\n",
            "Wall time: 15.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "instruction = \"あなたは優秀なAIモデルです。ユーザーの入力に対して回答とその理由を詳しく述べてください。\"\n",
        "input = \"\"\"\n",
        "日本の有名な観光地を理由と共に数を多く答えてください。\n",
        "\"\"\"\n",
        "print(generate(instruction, input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuSO5HDk2D0i",
        "outputId": "042b1062-c1ca-4b89-d1f1-812748f72644"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1.京都 - 日本有数の観光都市です。\n",
            "2.広島平和記念公園 - 現存する原爆ドームとともに、世界遺産に登録されています。\n",
            "3.宮崎市 - 神話や伝説の舞台である。\n",
            "CPU times: user 12.3 s, sys: 11.8 ms, total: 12.3 s\n",
            "Wall time: 12.3 s\n"
          ]
        }
      ]
    }
  ]
}