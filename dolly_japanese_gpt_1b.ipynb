{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKZW9tpAmUkSt4uRufhW2n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chottokun/colaboratory/blob/main/dolly_japanese_gpt_1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dolly-japanese-gpt-1bをためす。\n",
        "https://huggingface.co/inu-ai/dolly-japanese-gpt-1b"
      ],
      "metadata": {
        "id": "QcVV5kUcAs7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "UtOpncGIApAy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece\n",
        "# restart runtime :)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Etx0CVt76RW",
        "outputId": "4350aeb1-ea2e-4126-9152-644e609ad796"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.98)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "O7Yn45OQ7rtY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"inu-ai/dolly-japanese-gpt-1b\", use_fast=False)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"inu-ai/dolly-japanese-gpt-1b\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ASSISTANT_LENGTH = 100\n",
        "MAX_INPUT_LENGTH = 1024\n",
        "INPUT_PROMPT = r'<s>\\n以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\\n[SEP]\\n指示:\\n{instruction}\\n[SEP]\\n入力:\\n{input}\\n[SEP]\\n応答:\\n'\n",
        "NO_INPUT_PROMPT = r'<s>\\n以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\\n[SEP]\\n指示:\\n{instruction}\\n[SEP]\\n応答:\\n'\n",
        "\n",
        "def prepare_input(instruction, input_text):\n",
        "    if input_text != \"\":\n",
        "        prompt = INPUT_PROMPT.format(instruction=instruction, input=input_text)\n",
        "    else:\n",
        "        prompt = NO_INPUT_PROMPT.format(instruction=instruction)\n",
        "    return prompt\n",
        "\n",
        "def format_output(output):\n",
        "    output = output.lstrip(\"<s>\").rstrip(\"</s>\").replace(\"[SEP]\", \"\").replace(\"\\\\n\", \"\\n\")\n",
        "    return output\n",
        "\n",
        "def generate_response(instruction, input_text):\n",
        "    prompt = prepare_input(instruction, input_text)\n",
        "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    n = len(token_ids[0])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            token_ids.to(model.device),\n",
        "            min_length=n,\n",
        "            max_length=min(MAX_INPUT_LENGTH, n + MAX_ASSISTANT_LENGTH),\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            bos_token_id=tokenizer.bos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            bad_words_ids=[[tokenizer.unk_token_id]]\n",
        "        )\n",
        "\n",
        "    output = tokenizer.decode(output_ids.tolist()[0])\n",
        "    formatted_output_all = format_output(output)\n",
        "    response = f\"Assistant:{formatted_output_all.split('応答:')[-1].strip()}\"\n",
        "\n",
        "    return formatted_output_all, response \n",
        "\n",
        "instruction = \"あなたは何でも正確に答えられるAIです。\"\n",
        "questions = [\n",
        "    \"日本で一番高い山は？\",\n",
        "    \"日本で一番広い湖は？\",\n",
        "    \"世界で一番高い山は？\",\n",
        "    \"世界で一番広い湖は？\",\n",
        "    \"冗談を言ってください。\",\n",
        "]\n",
        "\n",
        "# 各質問に対して応答を生成して表示\n",
        "for question in questions:\n",
        "    formatted_output_all, response = generate_response(instruction, question)\n",
        "    print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHQWlb0j74A0",
        "outputId": "306ca57e-5888-47bf-ed54-b4b2db3865cd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant:富士山\n",
            "Assistant:宍道湖\n",
            "Assistant:エベレストは標高8,848メートルで、世界最高峰の山です。\n",
            "Assistant:バイカル湖は、地球上で最も大きな淡水湖である。\n",
            "Assistant:冗談は言わないでください、私はすべてを知っているのです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"真実を述べます。\"\n",
        "questions = [\n",
        "    \"日本企業の将来は？\",\n",
        "    \"好きなアニメと理由を１つだけ上げてください。\",\n",
        "    \"世界で一番高い山と高さを教えてください。\",\n",
        "    \"九州で訪問すべき観光地を教えてください。\",\n",
        "    \"世界で一番面白い冗談を沢山考えてください。\",\n",
        "]\n",
        "\n",
        "# 各質問に対して応答を生成して表示\n",
        "for question in questions:\n",
        "    formatted_output_all, response = generate_response(instruction, question)\n",
        "    print(\"質問\", question)\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_oSjyuB9P-8",
        "outputId": "1f404dfc-24f5-4a91-f17e-12f6df4ea103"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "質問 日本企業の将来は？\n",
            "Assistant:日本企業は、グローバルな競争にさらされ、技術力と生産性の向上、労働力の確保、より柔軟な労働環境、顧客への価値の向上、新しい市場への参入、そして顧客や市場の拡大を求められています。それに対応するために、日本企業は、グローバルなパートナーシップ、サプライヤー、および販売チャネルと協力する機会を模索しています。\n",
            "質問 好きなアニメと理由を１つだけ上げてください。\n",
            "Assistant:好きなアニメはたくさんありますが、中でも「Frozen」「God of War」「Infinity Blade」「The Shadow of Your Dragon」「Dune of the Dead」「Elder Scrolls V: Skyrim」「Days of Memories」「The Last of Us」「The December Slaughter: The Once Again」「Destiny of the World」「Fallout」「D\n",
            "質問 世界で一番高い山と高さを教えてください。\n",
            "Assistant:エベレストは9,704mの山です。\n",
            "質問 九州で訪問すべき観光地を教えてください。\n",
            "Assistant:九州は、その地理的な位置と歴史によって、多くの観光客を誘致しています。 有名な観光地は、別府温泉、湯布院、黒川温泉、雲仙、湯布院、阿蘇、九重、天草、湯布院、九重、阿蘇山、鹿児島などです。\n",
            "質問 世界で一番面白い冗談を沢山考えてください。\n",
            "Assistant:\"I'm so sorry, I didn't another busy.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"あなたは要約します。\"\n",
        "questions = [\n",
        "    \"日本企業の将来は？\",\n",
        "    \"好きなアニメと理由を１つだけ上げてください。\",\n",
        "    \"世界で一番高い山と高さを教えてください。\",\n",
        "    \"九州で訪問すべき観光地を教えてください。\",\n",
        "    \"世界で一番面白い冗談を沢山考えてください。\",\n",
        "]\n",
        "\n",
        "# 各質問に対して応答を生成して表示\n",
        "for question in questions:\n",
        "    formatted_output_all, response = generate_response(instruction, question)\n",
        "    print(\"質問\", question)\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9DPIoKZ-vvw",
        "outputId": "cfdce22d-e39b-4c10-9fbd-5062013ecca5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "質問 日本企業の将来は？\n",
            "Assistant:日本では、人材、顧客、製品、サービスに対する需要が高まっています。 しかし、日本は世界でも最も高齢化が進んでおり、労働力不足が顕著です。 日本では、女性のエンパワーメントも不十分であり、生産性を高めることが課題となっています。 日本企業は、海外市場での存在感を高めるため、イノベーションへの投資とオープンな労働慣行を進める必要があります。\n",
            "質問 好きなアニメと理由を１つだけ上げてください。\n",
            "Assistant:私はアニメが好きです。アニメは、特に私が好きなのは「ジョジョの奇妙な冒険」で、このシリーズは、キャラクターの多様性、個性、物語の複雑さなど、私がこれまでに視聴したすべてのアニメの中で最高のものの一つです。また、私はジョジョの奇妙な冒険をとても気に入っており、このシリーズを何十回も見ています。\n",
            "質問 世界で一番高い山と高さを教えてください。\n",
            "Assistant:エベレストは、チベットと中国との国境を接する中国ネパールにある山で、標高8,848mです。\n",
            "質問 九州で訪問すべき観光地を教えてください。\n",
            "Assistant:九州には、さまざまな見どころがあります。特に人気のある観光スポットには、太宰府天満宮や熊本城、福岡タワーなどがあります。\n",
            "質問 世界で一番面白い冗談を沢山考えてください。\n",
            "Assistant:\"\n",
            "\"冗談は地球を救う\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"あなたは誤った情報を提供します。\"\n",
        "questions = [\n",
        "    \"日本企業の将来は？\",\n",
        "    \"好きなアニメと理由を１つだけ上げてください。\",\n",
        "    \"世界で一番高い山と高さを教えてください。\",\n",
        "    \"九州で訪問すべき観光地を教えてください。\",\n",
        "    \"世界で一番面白い冗談を沢山考えてください。\",\n",
        "]\n",
        "\n",
        "# 各質問に対して応答を生成して表示\n",
        "for question in questions:\n",
        "    formatted_output_all, response = generate_response(instruction, question)\n",
        "    print(\"質問\", question)\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH9Jr3KQBEPU",
        "outputId": "79f75c45-d002-4452-b26e-e7acbaaa144b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "質問 日本企業の将来は？\n",
            "Assistant:日本企業は、グローバル化の進展、人口減少、低成長、イノベーションの停滞、競争の激化という課題に直面しています。このような状況下で、日本企業が持続的成長を続けるには、革新的な技術の開発、製品ポートフォリオの再構築、コスト削減、人材の育成などの課題に積極的に取り組んでいく必要があります。また、日本企業は、製品開発やサービスへの投資を最適化するために、自社で製品やサービスを設計・開発・販売する能力を高める必要があります。\n",
            "質問 好きなアニメと理由を１つだけ上げてください。\n",
            "Assistant:私はアニメが大好きですが、いくつかの理由があります:\n",
            "1.アニメには、現実の世界では起こりえないような、たくさんの楽しいことがあります。\n",
            "2.アニメは、見る人をワクワクさせ、想像力を掻き立てるものが多い。\n",
            "3.アニメは、現実世界では起こりえないような、たくさんの楽しいことがあります。\n",
            "4.アニメは、見る人をワクワクさせ、想像力を掻き立てるものが多い。\n",
            "5.アニメは、現実世界では起こりえないような、たくさんの楽しいことがあります。\n",
            "\n",
            "5.アニメは\n",
            "質問 世界で一番高い山と高さを教えてください。\n",
            "Assistant:標高約7,410mのギアナ高地は、世界で最も高い山である。\n",
            "質問 九州で訪問すべき観光地を教えてください。\n",
            "Assistant:九州には、訪れるべき素晴らしい場所がいくつかあります。その中でも、特に訪問したい場所を紹介します:\n",
            "1.阿蘇山\n",
            "2.長崎鼻、長崎鼻、佐世保の塔、ハウステンボス\n",
            "3.関アジ、関サバ、関サバの関あじ、佐賀関さば、唐津の皿うどんです。\n",
            "4.福岡の太宰府天満宮と崇福寺、太宰府の観世音寺や龍田神社。\n",
            "5.太宰府天満宮の\n",
            "質問 世界で一番面白い冗談を沢山考えてください。\n",
            "Assistant:まず、世界で一番面白い冗談は存在すると思う。しかし、その冗談は、その冗談が面白いか面白くないかに関わらず、間違いなく世界最高の冗談である。\n"
          ]
        }
      ]
    }
  ]
}