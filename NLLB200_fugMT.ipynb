{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN59Bw2O5MoBknoIWW3nnOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chottokun/colaboratory/blob/main/NLLB200_fugMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyo1VEYVmFYl",
        "outputId": "56bdfeed-3311-4624-af57-4d5c3e05112b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  5 04:31:18 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers sentencepiece pysbd"
      ],
      "metadata": {
        "id": "ayn7Nqakk-Uo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "MsgVPwiskx4C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysbd\n",
        "\n",
        "def nllb_transtate(text, from_lang, to_lang):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "  translated_tokens = model.generate(\n",
        "    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[to_lang], max_length=100\n",
        "  )\n",
        "  return tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "def nllb_transtate_ja_en(text):\n",
        "  seg_jp = pysbd.Segmenter(language=\"ja\", clean=False)\n",
        "  result=[]\n",
        "  for txt in seg_jp.segment(text):\n",
        "    result.append(nllb_transtate(txt, from_lang = \"jpn_Jpan\", to_lang = \"eng_Latn\"))\n",
        "  return \" \".join(result)\n",
        "\n",
        "def nllb_transtate_en_ja(text):\n",
        "  seg_jp = pysbd.Segmenter(language=\"en\", clean=False)\n",
        "  result=[]\n",
        "  for txt in seg_jp.segment(text):\n",
        "    result.append(nllb_transtate(txt, from_lang = \"eng_Latn\", to_lang = \"jpn_Jpan\"))\n",
        "  return \" \".join(result)"
      ],
      "metadata": {
        "id": "zvAP0pbZnz6j"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text = \"\"\"I had seen little of Holmes lately.\n",
        "My marriage had drifted us away from each other.\n",
        "\"\"\"\n",
        "# print(nllb_transtate(text, from_lang = \"eng_Latn\", to_lang = \"jpn_Jpan\"))\n",
        "\n",
        "print(\"no segment:\\n\",nllb_transtate(text, from_lang = \"eng_Latn\", to_lang = \"jpn_Jpan\"))\n",
        "print(\"segment:\\n\", nllb_transtate_en_ja(text)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu4wssIzk2ol",
        "outputId": "f13f20d1-26b0-475f-c6bf-4b611c7fb25e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no segment:\n",
            " 最近ホームズに会ったことがほとんどなかった 私の結婚は 私たちを離れさせた\n",
            "segment:\n",
            " 最近ホームズを見なかった 結婚は 私たちを離れさせた\n",
            "CPU times: user 6.43 s, sys: 142 ms, total: 6.57 s\n",
            "Wall time: 6.78 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text = \"\"\"最近はホームズとほとんど会っていなかった.\n",
        "私の結婚で私達の関係は疎遠になっていた.\n",
        "\"\"\"\n",
        "print(\"no segment:\\n\",nllb_transtate(text, from_lang = \"jpn_Jpan\", to_lang = \"eng_Latn\"))\n",
        "print(\"segment:\\n\", nllb_transtate_ja_en(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXPHiDEAlWhq",
        "outputId": "af083689-56ae-4695-918d-12a8fab6509c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no segment:\n",
            " I've been in a relationship with my husband, and my relationship with him has been very strained.\n",
            "segment:\n",
            " I've barely met with Holmes lately. My marriage had made our relationship distant.\n",
            "CPU times: user 10 s, sys: 86.3 ms, total: 10.1 s\n",
            "Wall time: 21.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers sentencepiece pysbd"
      ],
      "metadata": {
        "id": "GjHpWDO0gTXA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pysbd\n",
        "\n",
        "seg_en = pysbd.Segmenter(language=\"en\", clean=False)\n",
        "seg_jp = pysbd.Segmenter(language=\"ja\", clean=False)\n",
        "\n",
        "fugu_translator_en_ja = pipeline('translation', model='staka/fugumt-en-ja')\n",
        "fugu_translator_ja_en = pipeline('translation', model='staka/fugumt-ja-en')"
      ],
      "metadata": {
        "id": "GjEXyv__gAn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fugumt_transtate_en_ja(txt):\n",
        "  return fugu_translator_en_ja(seg_en.segment(txt))\n",
        "\n",
        "def fugumt_transtate_ja_en(txt):\n",
        "  return fugu_translator_ja_en(seg_jp.segment(txt))"
      ],
      "metadata": {
        "id": "Vcov7SixgjO0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"I had seen little of Holmes lately.\n",
        "My marriage had drifted us away from each other.\n",
        "\"\"\"\n",
        "print(fugumt_transtate_en_ja(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltuSsZYsguoy",
        "outputId": "96efeca8-69a0-4e13-e315-537e9b502fc0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'translation_text': '最近ホームズにほとんど会わなかった。'}, {'translation_text': '私の結婚は私たちをお互いから遠ざけていた。'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text = \"\"\"最近はホームズとほとんど会っていなかった.\n",
        "私の結婚で私達の関係は疎遠になっていた.\n",
        "\"\"\"\n",
        "print(fugumt_transtate_ja_en(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL1f-TApAJar",
        "outputId": "ab4e55f7-d55d-4c89-a803-fa7696c4ca06"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'translation_text': \"I haven't seen much of Holmes lately.\"}, {'translation_text': 'Our relationship was estranged by my marriage.'}]\n",
            "CPU times: user 2.14 s, sys: 10.9 ms, total: 2.15 s\n",
            "Wall time: 2.58 s\n"
          ]
        }
      ]
    }
  ]
}